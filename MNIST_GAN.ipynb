{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txU_As0hZvlK"
      },
      "source": [
        "Building Descriptor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKbJMIs-YU0C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# discriminator class\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        # initialise parent pytorch class\n",
        "        super().__init__()\n",
        "        \n",
        "                # define neural network layers\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(784, 200),\n",
        "            nn.LeakyReLU(0.02),\n",
        "\n",
        "            nn.LayerNorm(200),\n",
        "\n",
        "            nn.Linear(200, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # create loss function\n",
        "        self.loss_function = nn.BCELoss()\n",
        "\n",
        "        # create optimiser, simple stochastic gradient descent\n",
        "        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
        "        # counter and accumulator for progress\n",
        "        self.counter = 0;\n",
        "        self.progress = []\n",
        "\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        # simply run model\n",
        "        return self.model(inputs)\n",
        "    \n",
        "    \n",
        "    def train(self, inputs, targets):\n",
        "        # calculate the output of the network\n",
        "        outputs = self.forward(inputs)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = self.loss_function(outputs, targets)\n",
        "\n",
        "        # increase counter and accumulate error every 10\n",
        "        self.counter += 1;\n",
        "        if (self.counter % 10 == 0):\n",
        "            self.progress.append(loss.item())\n",
        "            pass\n",
        "        if (self.counter % 10000 == 0):\n",
        "            print(\"counter = \", self.counter)\n",
        "            pass\n",
        "\n",
        "        # zero gradients, perform a backward pass, update weights\n",
        "        self.optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimiser.step()\n",
        "\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def plot_progress(self):\n",
        "        df = pandas.DataFrame(self.progress, columns=['loss'])\n",
        "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
        "        pass\n",
        "    \n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcWMxSHGZ2U6"
      },
      "source": [
        "Building Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlrhTaG4Zrdf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# generator class\n",
        "class Generator(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        # initialise parent pytorch class\n",
        "        super().__init__()\n",
        "        \n",
        "        # define neural network layers\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(100, 200),\n",
        "            nn.LeakyReLU(0.02),\n",
        "\n",
        "            nn.LayerNorm(200),\n",
        "\n",
        "            nn.Linear(200, 784),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # create optimiser, simple stochastic gradient descent\n",
        "        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
        "\n",
        "        # counter and accumulator for progress\n",
        "        self.counter = 0;\n",
        "        self.progress = []\n",
        "        \n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def forward(self, inputs):        \n",
        "        # simply run model\n",
        "        return self.model(inputs)\n",
        "    \n",
        "    \n",
        "    def train(self, D, inputs, targets):\n",
        "        # calculate the output of the network\n",
        "        g_output = self.forward(inputs)\n",
        "        \n",
        "        # pass onto Discriminator\n",
        "        d_output = D.forward(g_output)\n",
        "        \n",
        "        # calculate error\n",
        "        loss = D.loss_function(d_output, targets)\n",
        "\n",
        "        # increase counter and accumulate error every 10\n",
        "        self.counter += 1;\n",
        "        if (self.counter % 10 == 0):\n",
        "            self.progress.append(loss.item())\n",
        "            pass\n",
        "\n",
        "        # zero gradients, perform a backward pass, update weights\n",
        "        self.optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimiser.step()\n",
        "\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def plot_progress(self):\n",
        "        df = pandas.DataFrame(self.progress, columns=['loss'])\n",
        "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
        "        pass\n",
        "    \n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDeQcxDTamgT",
        "outputId": "cbd5cc02-64fa-45f9-effd-fb387d50e7da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Dataset in /usr/local/lib/python3.7/dist-packages (1.5.2)\n",
            "Requirement already satisfied: banal>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from Dataset) (1.0.6)\n",
            "Requirement already satisfied: alembic>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from Dataset) (1.7.5)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from Dataset) (1.4.31)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic>=0.6.2->Dataset) (1.1.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic>=0.6.2->Dataset) (4.10.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=0.6.2->Dataset) (5.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.2->Dataset) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=0.6.2->Dataset) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=0.6.2->Dataset) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=0.6.2->Dataset) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install Dataset\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import pandas, numpy, random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# dataset class\n",
        "\n",
        "class MNISTDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, csv_file):\n",
        "        self.data_df = pandas.read_csv(csv_file, header=0)\n",
        "        pass\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # image target (label)\n",
        "        label = self.data_df.iloc[index,0]\n",
        "        target = torch.zeros((10))\n",
        "        target[label] = 1.0\n",
        "        \n",
        "        # image data, normalised from 0-255 to 0-1\n",
        "        image_values = torch.FloatTensor(self.data_df.iloc[index,1:].values) / 255.0\n",
        "        \n",
        "        # return label, image data tensor and target tensor\n",
        "        return label, image_values, target\n",
        "    \n",
        "    def plot_image(self, index):\n",
        "        img = self.data_df.iloc[index,1:].values.reshape(28,28)\n",
        "        plt.title(\"label = \" + str(self.data_df.iloc[index,0]))\n",
        "        plt.imshow(img, interpolation='none', cmap='Blues')\n",
        "        pass\n",
        "    \n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d19BY8PajCt",
        "outputId": "8e463c63-1190-467c-e0dd-4e15d86606a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch =  1\n",
            "counter =  10000\n",
            "counter =  20000\n",
            "counter =  30000\n",
            "counter =  40000\n",
            "counter =  50000\n",
            "counter =  60000\n",
            "counter =  70000\n",
            "counter =  80000\n",
            "counter =  90000\n",
            "counter =  100000\n",
            "counter =  110000\n",
            "counter =  120000\n",
            "epoch =  2\n",
            "counter =  130000\n",
            "counter =  140000\n",
            "counter =  150000\n",
            "counter =  160000\n",
            "counter =  170000\n",
            "counter =  180000\n",
            "counter =  190000\n",
            "counter =  200000\n",
            "counter =  210000\n",
            "counter =  220000\n",
            "counter =  230000\n",
            "counter =  240000\n",
            "epoch =  3\n",
            "counter =  250000\n",
            "counter =  260000\n",
            "counter =  270000\n",
            "counter =  280000\n",
            "counter =  290000\n",
            "counter =  300000\n",
            "counter =  310000\n",
            "counter =  320000\n",
            "counter =  330000\n",
            "counter =  340000\n",
            "counter =  350000\n",
            "counter =  360000\n",
            "epoch =  4\n",
            "counter =  370000\n",
            "counter =  380000\n",
            "counter =  390000\n",
            "counter =  400000\n",
            "counter =  410000\n",
            "counter =  420000\n",
            "counter =  430000\n",
            "counter =  440000\n",
            "counter =  450000\n",
            "counter =  460000\n",
            "counter =  470000\n",
            "counter =  480000\n",
            "epoch =  5\n",
            "counter =  490000\n",
            "counter =  500000\n",
            "counter =  510000\n",
            "counter =  520000\n",
            "counter =  530000\n",
            "counter =  540000\n",
            "counter =  550000\n",
            "counter =  560000\n",
            "counter =  570000\n",
            "counter =  580000\n",
            "counter =  590000\n",
            "counter =  600000\n",
            "epoch =  6\n",
            "counter =  610000\n",
            "counter =  620000\n",
            "counter =  630000\n",
            "counter =  640000\n",
            "counter =  650000\n",
            "counter =  660000\n",
            "counter =  670000\n",
            "counter =  680000\n",
            "counter =  690000\n",
            "counter =  700000\n",
            "counter =  710000\n",
            "counter =  720000\n",
            "epoch =  7\n",
            "counter =  730000\n",
            "counter =  740000\n",
            "counter =  750000\n",
            "counter =  760000\n",
            "counter =  770000\n",
            "counter =  780000\n",
            "counter =  790000\n",
            "counter =  800000\n",
            "counter =  810000\n",
            "counter =  820000\n",
            "counter =  830000\n",
            "counter =  840000\n",
            "epoch =  8\n",
            "counter =  850000\n",
            "counter =  860000\n",
            "counter =  870000\n",
            "counter =  880000\n",
            "counter =  890000\n",
            "counter =  900000\n",
            "counter =  910000\n",
            "counter =  920000\n",
            "counter =  930000\n",
            "counter =  940000\n",
            "counter =  950000\n",
            "counter =  960000\n",
            "epoch =  9\n",
            "counter =  970000\n",
            "counter =  980000\n",
            "counter =  990000\n",
            "counter =  1000000\n",
            "counter =  1010000\n",
            "counter =  1020000\n",
            "counter =  1030000\n",
            "counter =  1040000\n",
            "counter =  1050000\n",
            "counter =  1060000\n",
            "counter =  1070000\n",
            "counter =  1080000\n",
            "epoch =  10\n",
            "counter =  1090000\n",
            "counter =  1100000\n",
            "counter =  1110000\n",
            "counter =  1120000\n",
            "counter =  1130000\n",
            "counter =  1140000\n",
            "counter =  1150000\n",
            "counter =  1160000\n",
            "counter =  1170000\n",
            "counter =  1180000\n",
            "counter =  1190000\n",
            "counter =  1200000\n",
            "epoch =  11\n",
            "counter =  1210000\n",
            "counter =  1220000\n",
            "counter =  1230000\n",
            "counter =  1240000\n",
            "counter =  1250000\n",
            "counter =  1260000\n",
            "counter =  1270000\n",
            "counter =  1280000\n",
            "counter =  1290000\n",
            "counter =  1300000\n",
            "counter =  1310000\n",
            "counter =  1320000\n",
            "epoch =  12\n",
            "counter =  1330000\n",
            "counter =  1340000\n",
            "counter =  1350000\n",
            "counter =  1360000\n",
            "counter =  1370000\n",
            "counter =  1380000\n",
            "counter =  1390000\n",
            "counter =  1400000\n",
            "counter =  1410000\n",
            "counter =  1420000\n",
            "counter =  1430000\n",
            "counter =  1440000\n",
            "epoch =  13\n",
            "counter =  1450000\n",
            "counter =  1460000\n",
            "counter =  1470000\n",
            "counter =  1480000\n",
            "counter =  1490000\n",
            "counter =  1500000\n",
            "counter =  1510000\n",
            "counter =  1520000\n",
            "counter =  1530000\n",
            "counter =  1540000\n",
            "counter =  1550000\n",
            "counter =  1560000\n",
            "epoch =  14\n",
            "counter =  1570000\n",
            "counter =  1580000\n",
            "counter =  1590000\n",
            "counter =  1600000\n",
            "counter =  1610000\n",
            "counter =  1620000\n",
            "counter =  1630000\n",
            "counter =  1640000\n",
            "counter =  1650000\n",
            "counter =  1660000\n",
            "counter =  1670000\n",
            "counter =  1680000\n",
            "epoch =  15\n",
            "counter =  1690000\n",
            "counter =  1700000\n",
            "counter =  1710000\n",
            "counter =  1720000\n",
            "counter =  1730000\n",
            "counter =  1740000\n",
            "counter =  1750000\n",
            "counter =  1760000\n",
            "counter =  1770000\n",
            "counter =  1780000\n",
            "counter =  1790000\n",
            "counter =  1800000\n",
            "epoch =  16\n",
            "counter =  1810000\n",
            "counter =  1820000\n",
            "counter =  1830000\n",
            "counter =  1840000\n",
            "counter =  1850000\n",
            "counter =  1860000\n",
            "counter =  1870000\n",
            "counter =  1880000\n",
            "counter =  1890000\n",
            "counter =  1900000\n",
            "counter =  1910000\n",
            "counter =  1920000\n",
            "epoch =  17\n",
            "counter =  1930000\n",
            "counter =  1940000\n",
            "counter =  1950000\n",
            "counter =  1960000\n",
            "counter =  1970000\n",
            "counter =  1980000\n",
            "counter =  1990000\n",
            "counter =  2000000\n",
            "counter =  2010000\n",
            "counter =  2020000\n",
            "counter =  2030000\n",
            "counter =  2040000\n",
            "epoch =  18\n",
            "counter =  2050000\n",
            "counter =  2060000\n",
            "counter =  2070000\n",
            "counter =  2080000\n",
            "counter =  2090000\n",
            "counter =  2100000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "#from Dataset import FMnistDataset\n",
        "#from Discriminator import Discriminator\n",
        "#from Generator import Generator\n",
        "\n",
        "# load data\n",
        "fmnist_dataset = MNISTDataset('/content/drive/MyDrive/Tutorials/Homework/GAN/mnist_train.csv')\n",
        "\n",
        "# functions to generate random data\n",
        "def generate_random_image(size):\n",
        "    random_data = torch.rand(size)\n",
        "    return random_data\n",
        "\n",
        "\n",
        "def generate_random_seed(size):\n",
        "    random_data = torch.randn(size)\n",
        "    return random_data\n",
        "\n",
        "# create Discriminator and Generator\n",
        "\n",
        "D = Discriminator()\n",
        "G = Generator()\n",
        "\n",
        "epochs = 2000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print (\"epoch = \", epoch + 1)\n",
        "  # train Discriminator and Generator\n",
        "  for label, image_data_tensor, target_tensor in fmnist_dataset:\n",
        "    # train discriminator on true\n",
        "    D.train(image_data_tensor, torch.FloatTensor([1.0]))\n",
        "    \n",
        "    # train discriminator on false\n",
        "    # use detach() so gradients in G are not calculated\n",
        "    D.train(G.forward(generate_random_seed(100)).detach(), torch.FloatTensor([0.0]))\n",
        "    \n",
        "    # train generator\n",
        "    G.train(D, generate_random_seed(100), torch.FloatTensor([1.0]))\n",
        "\n",
        "    pass\n",
        "    \n",
        "  pass\n",
        "\n",
        "# plot several outputs from the trained generator\n",
        "# plot a 3 column, 2 row array of generated images\n",
        "f, axarr = plt.subplots(2,3, figsize=(16,8))\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "        output = G.forward(generate_random_seed(100))\n",
        "        img = output.detach().numpy().reshape(28,28)\n",
        "        axarr[i,j].imshow(img, interpolation='none', cmap='Blues')\n",
        "        pass\n",
        "    pass\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": " MNIST-GAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}